{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pahrul23/pahrul-skripsi/blob/main/SKRIPSI_PAHRUL_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVbFCPIspaam"
      },
      "source": [
        "# **LOAD** **DAN** **PREPROCESSING** **DATA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29Jiecryw4rS",
        "outputId": "af69fe08-e7bb-47be-f70f-db11d64f8631"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (3.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from nltk) (4.65.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk) (8.1.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.9/dist-packages (from nltk) (2022.6.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk) (1.2.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting Sastrawi\n",
            "  Downloading Sastrawi-1.0.1-py2.py3-none-any.whl (209 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.7/209.7 KB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Sastrawi\n",
            "Successfully installed Sastrawi-1.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk\n",
        "!pip install Sastrawi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F7-mVBkWYih3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OyPfSzE-xn1x"
      },
      "outputs": [],
      "source": [
        "df_dataTraining = pd.read_csv('drive/MyDrive/Wira/labelV1.csv', encoding=\"ISO-8859-1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        },
        "id": "M32ZoOXcxqX8",
        "outputId": "111eee44-b758-4dec-c966-9220261466f8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       label                                           filtered  \\\n",
              "0        1.0                                             mantap   \n",
              "1       -1.0  kenapa saya ditagih hutang kan saya di tolak p...   \n",
              "2        1.0                                       sangat bagus   \n",
              "3        1.0                                              bagus   \n",
              "4        1.0  ini pengajuan pertama moga di acc krn lg butuh...   \n",
              "...      ...                                                ...   \n",
              "17636   -1.0                                   ada kami ngentod   \n",
              "17637   -1.0  waktu jatuh tempo masih hari tapi panggilan ma...   \n",
              "17638   -1.0  pelayanan dan csnya buruk blum waktunya byar s...   \n",
              "17639   -1.0  aplikasi busuk baru daftar udah di tolak penga...   \n",
              "17640   -1.0                       hadeh apk apaan sih ga jelas   \n",
              "\n",
              "                                                 cleaned  \\\n",
              "0                                                 mantap   \n",
              "1      kenapa saya tagih hutang saya tolak pinjam man...   \n",
              "2                                           sangat bagus   \n",
              "3                                                  bagus   \n",
              "4      aju pertama moga acc lg butuh dana kembang war...   \n",
              "...                                                  ...   \n",
              "17636                                   ada kami ngentod   \n",
              "17637  jatuh tempo masih hari tapi panggil masuk tagi...   \n",
              "17638  layan csnya buruk blum waktu byar sdah tagih k...   \n",
              "17639  aplikasi busuk baru daftar udah tolak aju pinj...   \n",
              "17640                             hadeh apk apa ga jelas   \n",
              "\n",
              "                                          content_tokens  \\\n",
              "0                                             ['mantap']   \n",
              "1      ['kenapa', 'saya', 'tagih', 'hutang', 'saya', ...   \n",
              "2                                    ['sangat', 'bagus']   \n",
              "3                                              ['bagus']   \n",
              "4      ['aju', 'pertama', 'moga', 'acc', 'lg', 'butuh...   \n",
              "...                                                  ...   \n",
              "17636                         ['ada', 'kami', 'ngentod']   \n",
              "17637  ['jatuh', 'tempo', 'masih', 'hari', 'tapi', 'p...   \n",
              "17638  ['layan', 'csnya', 'buruk', 'blum', 'waktu', '...   \n",
              "17639  ['aplikasi', 'busuk', 'baru', 'daftar', 'udah'...   \n",
              "17640             ['hadeh', 'apk', 'apa', 'ga', 'jelas']   \n",
              "\n",
              "                                             normalisasi  \n",
              "0                                             ['mantap']  \n",
              "1      ['kenapa', 'aku', 'tagih', 'hutang', 'aku', 't...  \n",
              "2                                    ['sangat', 'bagus']  \n",
              "3                                              ['bagus']  \n",
              "4      ['aju', 'pertama', 'semoga', 'terima', 'lagi',...  \n",
              "...                                                  ...  \n",
              "17636                         ['ada', 'kami', 'ngentod']  \n",
              "17637  ['jatuh', 'tempo', 'masih', 'hari', 'tapi', 'p...  \n",
              "17638  ['layan', 'csnya', 'buruk', 'blum', 'waktu', '...  \n",
              "17639  ['aplikasi', 'busuk', 'baru', 'daftar', 'sudah...  \n",
              "17640      ['aduh', 'aplikasi', 'apa', 'tidak', 'jelas']  \n",
              "\n",
              "[17641 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f6592496-a28d-46de-9c85-e205f4c9a45b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>filtered</th>\n",
              "      <th>cleaned</th>\n",
              "      <th>content_tokens</th>\n",
              "      <th>normalisasi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>mantap</td>\n",
              "      <td>mantap</td>\n",
              "      <td>['mantap']</td>\n",
              "      <td>['mantap']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.0</td>\n",
              "      <td>kenapa saya ditagih hutang kan saya di tolak p...</td>\n",
              "      <td>kenapa saya tagih hutang saya tolak pinjam man...</td>\n",
              "      <td>['kenapa', 'saya', 'tagih', 'hutang', 'saya', ...</td>\n",
              "      <td>['kenapa', 'aku', 'tagih', 'hutang', 'aku', 't...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>sangat bagus</td>\n",
              "      <td>sangat bagus</td>\n",
              "      <td>['sangat', 'bagus']</td>\n",
              "      <td>['sangat', 'bagus']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>bagus</td>\n",
              "      <td>bagus</td>\n",
              "      <td>['bagus']</td>\n",
              "      <td>['bagus']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>ini pengajuan pertama moga di acc krn lg butuh...</td>\n",
              "      <td>aju pertama moga acc lg butuh dana kembang war...</td>\n",
              "      <td>['aju', 'pertama', 'moga', 'acc', 'lg', 'butuh...</td>\n",
              "      <td>['aju', 'pertama', 'semoga', 'terima', 'lagi',...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17636</th>\n",
              "      <td>-1.0</td>\n",
              "      <td>ada kami ngentod</td>\n",
              "      <td>ada kami ngentod</td>\n",
              "      <td>['ada', 'kami', 'ngentod']</td>\n",
              "      <td>['ada', 'kami', 'ngentod']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17637</th>\n",
              "      <td>-1.0</td>\n",
              "      <td>waktu jatuh tempo masih hari tapi panggilan ma...</td>\n",
              "      <td>jatuh tempo masih hari tapi panggil masuk tagi...</td>\n",
              "      <td>['jatuh', 'tempo', 'masih', 'hari', 'tapi', 'p...</td>\n",
              "      <td>['jatuh', 'tempo', 'masih', 'hari', 'tapi', 'p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17638</th>\n",
              "      <td>-1.0</td>\n",
              "      <td>pelayanan dan csnya buruk blum waktunya byar s...</td>\n",
              "      <td>layan csnya buruk blum waktu byar sdah tagih k...</td>\n",
              "      <td>['layan', 'csnya', 'buruk', 'blum', 'waktu', '...</td>\n",
              "      <td>['layan', 'csnya', 'buruk', 'blum', 'waktu', '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17639</th>\n",
              "      <td>-1.0</td>\n",
              "      <td>aplikasi busuk baru daftar udah di tolak penga...</td>\n",
              "      <td>aplikasi busuk baru daftar udah tolak aju pinj...</td>\n",
              "      <td>['aplikasi', 'busuk', 'baru', 'daftar', 'udah'...</td>\n",
              "      <td>['aplikasi', 'busuk', 'baru', 'daftar', 'sudah...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17640</th>\n",
              "      <td>-1.0</td>\n",
              "      <td>hadeh apk apaan sih ga jelas</td>\n",
              "      <td>hadeh apk apa ga jelas</td>\n",
              "      <td>['hadeh', 'apk', 'apa', 'ga', 'jelas']</td>\n",
              "      <td>['aduh', 'aplikasi', 'apa', 'tidak', 'jelas']</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>17641 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f6592496-a28d-46de-9c85-e205f4c9a45b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f6592496-a28d-46de-9c85-e205f4c9a45b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f6592496-a28d-46de-9c85-e205f4c9a45b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "df_dataTraining"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aah8U5x52dY0",
        "outputId": "7089397d-e6c7-429b-a4fb-8f00661ba153"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1.0    7783\n",
            "-1.0    7736\n",
            " 0.0    2121\n",
            "Name: label, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(df_dataTraining['label'].value_counts())\n",
        "# print(df_dataTraining.value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4ksd3CsjWir"
      },
      "outputs": [],
      "source": [
        "df_dataTraining['label'] = df_dataTraining['label'].replace([1], '2')\n",
        "df_dataTraining['label'] = df_dataTraining['label'].replace([-1], '1')\n",
        "df_dataTraining['label'] = df_dataTraining['label'].replace([0], '0')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "blcNnGjljaY2",
        "outputId": "015d18a3-bd40-45fc-de16-63d45e87ca0a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    7783\n",
              "1    7736\n",
              "0    2121\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "df_dataTraining['label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2 Untuk Positif\n",
        "#1 Untuk Negatif\n",
        "#0 Untuk Netral"
      ],
      "metadata": {
        "id": "uxVwmK5dHbpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "Ljq0jJ6K2WVV",
        "outputId": "c60d92aa-626a-4da0-9f47-d15c5a3aefcc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/seaborn/_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<AxesSubplot:xlabel='label', ylabel='count'>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEGCAYAAACUzrmNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAAVF0lEQVR4nO3df7DddZ3f8edLouJvAtymbJLdMGvGLdqKcAdw6eysUkNgt4ZuKcWukqXpZGfK6trtL+x0Sova0dldKdrKTGaJBqsii1oyLSPNRHd31lHgBlkQIuWuikkGyF0SQddRN+y7f5zP1WNy4/eEvd9zc3Ofj5kz5/t9fz/f73mfuUNefH+eVBWSJP00z1voBiRJxz/DQpLUybCQJHUyLCRJnQwLSVKnZQvdQB9OP/30WrNmzUK3IUmLyq5du/6iqibmWnZChsWaNWuYmppa6DYkaVFJ8tjRlvV6GCrJv0ryUJKvJvlkkpOTnJnk7iTTST6V5AVt7Avb/HRbvmZoO+9q9UeSXNxnz5KkI/UWFklWAu8AJqvqNcBJwJXA+4EbquqVwEFgU1tlE3Cw1W9o40hyVlvv1cB64MNJTuqrb0nSkfo+wb0MeFGSZcCLgceBNwK3t+XbgMva9IY2T1t+UZK0+q1V9YOq+gYwDZzXc9+SpCG9hUVV7QN+D/gWg5B4GtgFfLuqDrVhe4GVbXolsKete6iNP224Psc6P5Jkc5KpJFMzMzPz/4UkaQnr8zDUcgZ7BWcCPwO8hMFhpF5U1ZaqmqyqyYmJOU/mS5Keoz4PQ/0D4BtVNVNVfwV8BrgQOKUdlgJYBexr0/uA1QBt+SuAp4brc6wjSRqDPsPiW8AFSV7czj1cBDwMfAG4vI3ZCNzRpre3edryz9fgkbjbgSvb1VJnAmuBe3rsW5J0mN7us6iqu5PcDtwHHAK+AmwB/g9wa5L3tNrNbZWbgY8lmQYOMLgCiqp6KMltDILmEHBNVT3bV9+SpCPlRPw9i8nJyfKmPEk6Nkl2VdXkXMtOyDu4j8W5//aWhW5hSdj1u1ctdAuS/gaWfFhocfvW9X93oVs44f3sf3pwoVvQccCnzkqSOhkWkqROhoUkqZNhIUnqZFhIkjoZFpKkToaFJKmTYSFJ6mRYSJI6GRaSpE6GhSSpk2EhSepkWEiSOhkWkqROhoUkqVNvYZHkVUnuH3o9k+SdSU5NsiPJo+19eRufJB9MMp3kgSTnDG1rYxv/aJKNR/9USVIfeguLqnqkqs6uqrOBc4HvAZ8FrgV2VtVaYGebB7gEWNtem4GbAJKcClwHnA+cB1w3GzCSpPEY12Goi4A/r6rHgA3AtlbfBlzWpjcAt9TAl4FTkpwBXAzsqKoDVXUQ2AGsH1PfkiTGFxZXAp9s0yuq6vE2/QSwok2vBPYMrbO31Y5WlySNSe9hkeQFwJuBPzx8WVUVUPP0OZuTTCWZmpmZmY9NSpKacexZXALcV1VPtvkn2+El2vv+Vt8HrB5ab1WrHa3+E6pqS1VNVtXkxMTEPH8FSVraxhEWb+HHh6AAtgOzVzRtBO4Yql/Vroq6AHi6Ha66C1iXZHk7sb2u1SRJY7Ksz40neQnwJuA3h8rvA25Lsgl4DLii1e8ELgWmGVw5dTVAVR1I8m7g3jbu+qo60GffkqSf1GtYVNVfAqcdVnuKwdVRh48t4JqjbGcrsLWPHiVJ3byDW5LUybCQJHUyLCRJnQwLSVInw0KS1MmwkCR1MiwkSZ0MC0lSJ8NCktTJsJAkdTIsJEmdDAtJUifDQpLUybCQJHUyLCRJnQwLSVInw0KS1MmwkCR16jUskpyS5PYkX0uyO8nrk5yaZEeSR9v78jY2ST6YZDrJA0nOGdrOxjb+0SQb++xZknSkvvcsbgQ+V1W/ALwW2A1cC+ysqrXAzjYPcAmwtr02AzcBJDkVuA44HzgPuG42YCRJ49FbWCR5BfBLwM0AVfXDqvo2sAHY1oZtAy5r0xuAW2rgy8ApSc4ALgZ2VNWBqjoI7ADW99W3JOlIfe5ZnAnMAB9J8pUkf5DkJcCKqnq8jXkCWNGmVwJ7htbf22pHq/+EJJuTTCWZmpmZmeevIklLW59hsQw4B7ipql4H/CU/PuQEQFUVUPPxYVW1paomq2pyYmJiPjYpSWr6DIu9wN6qurvN384gPJ5sh5do7/vb8n3A6qH1V7Xa0eqSpDHpLSyq6glgT5JXtdJFwMPAdmD2iqaNwB1tejtwVbsq6gLg6Xa46i5gXZLl7cT2ulaTJI3Jsp63/3bg40leAHwduJpBQN2WZBPwGHBFG3sncCkwDXyvjaWqDiR5N3BvG3d9VR3ouW9J0pBew6Kq7gcm51h00RxjC7jmKNvZCmyd1+YkSSPzDm5JUifDQpLUybCQJHUyLCRJnQwLSVInw0KS1MmwkCR1MiwkSZ0MC0lSJ8NCktTJsJAkdTIsJEmdDAtJUifDQpLUybCQJHUyLCRJnQwLSVInw0KS1KnXsEjyzSQPJrk/yVSrnZpkR5JH2/vyVk+SDyaZTvJAknOGtrOxjX80ycY+e5YkHWkcexZvqKqzq2r2t7ivBXZW1VpgZ5sHuARY216bgZtgEC7AdcD5wHnAdbMBI0kaj4U4DLUB2NamtwGXDdVvqYEvA6ckOQO4GNhRVQeq6iCwA1g/5p4laUnrOywK+L9JdiXZ3GorqurxNv0EsKJNrwT2DK27t9WOVv8JSTYnmUoyNTMzM5/fQZKWvGU9b//vV9W+JH8L2JHka8MLq6qS1Hx8UFVtAbYATE5Ozss2JUkDve5ZVNW+9r4f+CyDcw5PtsNLtPf9bfg+YPXQ6qta7Wh1SdKY9BYWSV6S5GWz08A64KvAdmD2iqaNwB1tejtwVbsq6gLg6Xa46i5gXZLl7cT2ulaTJI1Jn4ehVgCfTTL7OZ+oqs8luRe4Lckm4DHgijb+TuBSYBr4HnA1QFUdSPJu4N427vqqOtBj35Kkw/QWFlX1deC1c9SfAi6ao17ANUfZ1lZg63z3KEkajXdwS5I6GRaSpE6GhSSpk2EhSepkWEiSOhkWkqROhoUkqdNIYZFk5yg1SdKJ6afelJfkZODFwOntURtpi17OHE9+lSSdmLru4P5N4J3AzwC7+HFYPAP89/7akiQdT35qWFTVjcCNSd5eVR8aU0+SpOPMSM+GqqoPJflFYM3wOlV1S099SZKOIyOFRZKPAT8P3A8828oFGBaStASM+tTZSeCs9mRYSdISM+p9Fl8F/nafjUiSjl+j7lmcDjyc5B7gB7PFqnpzL11Jko4ro4bFf+6zCUnS8W3Uq6H++Ll+QJKTgClgX1X9apIzgVuB0xjcu/G2qvphkhcyOGF+LvAU8E+r6pttG+8CNjE4uf6OqvI3uCVpjEZ93Md3kjzTXt9P8mySZ0b8jN8Gdg/Nvx+4oapeCRxkEAK094OtfkMbR5KzgCuBVwPrgQ+3AJIkjclIYVFVL6uql1fVy4EXAf8Y+HDXeklWAb8C/EGbD/BG4PY2ZBtwWZve0OZpyy9q4zcAt1bVD6rqG8A0cN4ofUuS5scxP3W2Bv4XcPEIw/8b8O+Av27zpwHfrqpDbX4vP37G1EpgT/uMQ8DTbfyP6nOs8yNJNieZSjI1MzNzLF9JktRh1Jvyfm1o9nkM7rv4fsc6vwrsr6pdSX75uTY4qqraAmwBmJyc9H4QSZpHo14N9Q+Hpg8B32RweOinuRB4c5JLgZMZPKn2RuCUJMva3sMqYF8bvw9YDexNsgx4BYMT3bP1WcPrSJLGYNSroa4+1g1X1buAdwG0PYt/U1W/nuQPgcsZXBG1EbijrbK9zX+pLf98VVWS7cAnknyAwdNv1wL3HGs/kqTnbtSroVYl+WyS/e316Xby+rn498DvJJlmcE7i5la/GTit1X8HuBagqh4CbgMeBj4HXFNVzx6xVUlSb0Y9DPUR4BPAP2nzb221N42yclX9EfBHbfrrzHE1U1V9f2j7hy97L/DeEXuVJM2zUa+Gmqiqj1TVofb6KDDRY1+SpOPIqGHxVJK3Jjmpvd7K4OSzJGkJGDUs/jlwBfAE8DiDE9C/0VNPkqTjzKjnLK4HNlbVQYAkpwK/xyBEJEknuFH3LP7ebFAAVNUB4HX9tCRJOt6MGhbPS7J8dqbtWYy6VyJJWuRG/Qf/94EvtRvqYHCJq5eyStISMeod3LckmWLwxFiAX6uqh/trS5J0PBn5UFILBwNCkpagY35EuSRp6TEsJEmdDAtJUifDQpLUybCQJHUyLCRJnQwLSVInw0KS1MmwkCR16i0skpyc5J4kf5bkoST/pdXPTHJ3kukkn0ryglZ/YZufbsvXDG3rXa3+SJKL++pZkjS3PvcsfgC8sapeC5wNrE9yAfB+4IaqeiVwENjUxm8CDrb6DW0cSc4CrgReDawHPpzkpB77liQdprewqIHvttnnt1cxeBjh7a2+DbisTW9o87TlFyVJq99aVT+oqm8A08B5ffUtSTpSr+cs2u913w/sB3YAfw58u6oOtSF7gZVteiWwB6Atfxo4bbg+xzrDn7U5yVSSqZmZmR6+jSQtXb2GRVU9W1VnA6sY7A38Qo+ftaWqJqtqcmJioq+PkaQlaSxXQ1XVt4EvAK8HTkky+2j0VcC+Nr0PWA3Qlr8CeGq4Psc6kqQx6PNqqIkkp7TpFwFvAnYzCI3L27CNwB1tenubpy3/fFVVq1/ZrpY6E1gL3NNX35KkI/X5O9pnANvalUvPA26rqv+d5GHg1iTvAb4C3NzG3wx8LMk0cIDBFVBU1UNJbmPww0uHgGuq6tke+5YkHaa3sKiqB4DXzVH/OnNczVRV32fw295zbeu9+JvfkrRgvINbktTJsJAkdTIsJEmdDAtJUifDQpLUybCQJHUyLCRJnQwLSVInw0KS1MmwkCR1MiwkSZ0MC0lSJ8NCktTJsJAkdTIsJEmdDAtJUifDQpLUqbdfykuyGrgFWAEUsKWqbkxyKvApYA3wTeCKqjqYJMCNwKXA94DfqKr72rY2Av+xbfo9VbWtr74ljc+FH7pwoVs44X3x7V+cl+30uWdxCPjXVXUWcAFwTZKzgGuBnVW1FtjZ5gEuAda212bgJoAWLtcB5zP4OdbrkizvsW9J0mF6C4uqenx2z6CqvgPsBlYCG4DZPYNtwGVtegNwSw18GTglyRnAxcCOqjpQVQeBHcD6vvqWJB1pLOcskqwBXgfcDayoqsfboicYHKaCQZDsGVptb6sdrS5JGpPewyLJS4FPA++sqmeGl1VVMTifMR+fsznJVJKpmZmZ+dikJKnpNSySPJ9BUHy8qj7Tyk+2w0u09/2tvg9YPbT6qlY7Wv0nVNWWqpqsqsmJiYn5/SKStMT1Fhbt6qabgd1V9YGhRduBjW16I3DHUP2qDFwAPN0OV90FrEuyvJ3YXtdqkqQx6e3SWeBC4G3Ag0nub7X/ALwPuC3JJuAx4Iq27E4Gl81OM7h09mqAqjqQ5N3AvW3c9VV1oMe+JUmH6S0squpPgRxl8UVzjC/gmqNsayuwdf66kyQdC+/gliR1MiwkSZ0MC0lSJ8NCktTJsJAkdTIsJEmdDAtJUifDQpLUybCQJHUyLCRJnQwLSVInw0KS1MmwkCR1MiwkSZ0MC0lSJ8NCktTJsJAkdTIsJEmdeguLJFuT7E/y1aHaqUl2JHm0vS9v9ST5YJLpJA8kOWdonY1t/KNJNvbVryTp6Prcs/gosP6w2rXAzqpaC+xs8wCXAGvbazNwEwzCBbgOOB84D7huNmAkSePTW1hU1Z8ABw4rbwC2teltwGVD9Vtq4MvAKUnOAC4GdlTVgao6COzgyACSJPVs3OcsVlTV4236CWBFm14J7Bkat7fVjlY/QpLNSaaSTM3MzMxv15K0xC3YCe6qKqDmcXtbqmqyqiYnJibma7OSJMYfFk+2w0u09/2tvg9YPTRuVasdrS5JGqNxh8V2YPaKpo3AHUP1q9pVURcAT7fDVXcB65Isbye217WaJGmMlvW14SSfBH4ZOD3JXgZXNb0PuC3JJuAx4Io2/E7gUmAa+B5wNUBVHUjybuDeNu76qjr8pLkkqWe9hUVVveUoiy6aY2wB1xxlO1uBrfPYmiTpGHkHtySpk2EhSepkWEiSOhkWkqROhoUkqZNhIUnqZFhIkjoZFpKkToaFJKmTYSFJ6mRYSJI6GRaSpE6GhSSpk2EhSepkWEiSOhkWkqROhoUkqZNhIUnqtGjCIsn6JI8kmU5y7UL3I0lLyaIIiyQnAf8DuAQ4C3hLkrMWtitJWjoWRVgA5wHTVfX1qvohcCuwYYF7kqQlI1W10D10SnI5sL6q/kWbfxtwflX91tCYzcDmNvsq4JGxNzo+pwN/sdBN6Dnz77d4neh/u5+rqom5Fiwbdyd9qaotwJaF7mMckkxV1eRC96Hnxr/f4rWU/3aL5TDUPmD10PyqVpMkjcFiCYt7gbVJzkzyAuBKYPsC9yRJS8aiOAxVVYeS/BZwF3ASsLWqHlrgthbSkjjcdgLz77d4Ldm/3aI4wS1JWliL5TCUJGkBGRaSpE6GxSKSZHWSLyR5OMlDSX57oXvS6JJsTbI/yVcXuhcdu6X+yCHPWSwiSc4Azqiq+5K8DNgFXFZVDy9waxpBkl8CvgvcUlWvWeh+NLr2yKH/B7wJ2MvgCs23LKX/9tyzWESq6vGquq9NfwfYDaxc2K40qqr6E+DAQveh52TJP3LIsFikkqwBXgfcvcCtSEvBSmDP0Pxeltj/qBkWi1CSlwKfBt5ZVc8sdD+STnyGxSKT5PkMguLjVfWZhe5HWiKW/COHDItFJEmAm4HdVfWBhe5HWkKW/COHDIvF5ULgbcAbk9zfXpcudFMaTZJPAl8CXpVkb5JNC92TRlNVh4DZRw7tBm5bao8c8tJZSVIn9ywkSZ0MC0lSJ8NCktTJsJAkdTIsJEmdDAtpHiT5bsfyNcf6tNkkH01y+d+sM2l+GBaSpE6GhTSPkrw0yc4k9yV5MMnwk0mXJfl4kt1Jbk/y4rbOuUn+OMmuJHe1R9FLxxXDQppf3wf+UVWdA7wB+P32mBaAVwEfrqq/AzwD/Mv2rK8PAZdX1bnAVuC9C9C39FMtW+gGpBNMgP/afujorxk8xnpFW7anqr7Ypv8n8A7gc8BrgB0tU04CHh9rx9IIDAtpfv06MAGcW1V/leSbwMlt2eHP1ikG4fJQVb1+fC1Kx87DUNL8egWwvwXFG4CfG1r2s0lmQ+GfAX8KPAJMzNaTPD/Jq8fasTQCw0KaXx8HJpM8CFwFfG1o2SPANUl2A8uBm9pPdF4OvD/JnwH3A7843palbj51VpLUyT0LSVInw0KS1MmwkCR1MiwkSZ0MC0lSJ8NCktTJsJAkdfr/d8oZ0nEzMXUAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "sns.countplot(df_dataTraining['label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        },
        "id": "W2qWBgDxyFWB",
        "outputId": "f097386e-331e-4a63-91a4-03adc1803973"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      label                                           filtered  \\\n",
              "0         2                                             mantap   \n",
              "1         1  kenapa saya ditagih hutang kan saya di tolak p...   \n",
              "2         2                                       sangat bagus   \n",
              "3         2                                              bagus   \n",
              "4         2  ini pengajuan pertama moga di acc krn lg butuh...   \n",
              "...     ...                                                ...   \n",
              "17636     1                                   ada kami ngentod   \n",
              "17637     1  waktu jatuh tempo masih hari tapi panggilan ma...   \n",
              "17638     1  pelayanan dan csnya buruk blum waktunya byar s...   \n",
              "17639     1  aplikasi busuk baru daftar udah di tolak penga...   \n",
              "17640     1                       hadeh apk apaan sih ga jelas   \n",
              "\n",
              "                                                 cleaned  \\\n",
              "0                                                 mantap   \n",
              "1      kenapa saya tagih hutang saya tolak pinjam man...   \n",
              "2                                           sangat bagus   \n",
              "3                                                  bagus   \n",
              "4      aju pertama moga acc lg butuh dana kembang war...   \n",
              "...                                                  ...   \n",
              "17636                                   ada kami ngentod   \n",
              "17637  jatuh tempo masih hari tapi panggil masuk tagi...   \n",
              "17638  layan csnya buruk blum waktu byar sdah tagih k...   \n",
              "17639  aplikasi busuk baru daftar udah tolak aju pinj...   \n",
              "17640                             hadeh apk apa ga jelas   \n",
              "\n",
              "                                          content_tokens  \\\n",
              "0                                             ['mantap']   \n",
              "1      ['kenapa', 'saya', 'tagih', 'hutang', 'saya', ...   \n",
              "2                                    ['sangat', 'bagus']   \n",
              "3                                              ['bagus']   \n",
              "4      ['aju', 'pertama', 'moga', 'acc', 'lg', 'butuh...   \n",
              "...                                                  ...   \n",
              "17636                         ['ada', 'kami', 'ngentod']   \n",
              "17637  ['jatuh', 'tempo', 'masih', 'hari', 'tapi', 'p...   \n",
              "17638  ['layan', 'csnya', 'buruk', 'blum', 'waktu', '...   \n",
              "17639  ['aplikasi', 'busuk', 'baru', 'daftar', 'udah'...   \n",
              "17640             ['hadeh', 'apk', 'apa', 'ga', 'jelas']   \n",
              "\n",
              "                                             normalisasi  \n",
              "0                                             ['mantap']  \n",
              "1      ['kenapa', 'aku', 'tagih', 'hutang', 'aku', 't...  \n",
              "2                                    ['sangat', 'bagus']  \n",
              "3                                              ['bagus']  \n",
              "4      ['aju', 'pertama', 'semoga', 'terima', 'lagi',...  \n",
              "...                                                  ...  \n",
              "17636                         ['ada', 'kami', 'ngentod']  \n",
              "17637  ['jatuh', 'tempo', 'masih', 'hari', 'tapi', 'p...  \n",
              "17638  ['layan', 'csnya', 'buruk', 'blum', 'waktu', '...  \n",
              "17639  ['aplikasi', 'busuk', 'baru', 'daftar', 'sudah...  \n",
              "17640      ['aduh', 'aplikasi', 'apa', 'tidak', 'jelas']  \n",
              "\n",
              "[17641 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fa4176d7-e3e3-42a9-b435-f21900b815e6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>filtered</th>\n",
              "      <th>cleaned</th>\n",
              "      <th>content_tokens</th>\n",
              "      <th>normalisasi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>mantap</td>\n",
              "      <td>mantap</td>\n",
              "      <td>['mantap']</td>\n",
              "      <td>['mantap']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>kenapa saya ditagih hutang kan saya di tolak p...</td>\n",
              "      <td>kenapa saya tagih hutang saya tolak pinjam man...</td>\n",
              "      <td>['kenapa', 'saya', 'tagih', 'hutang', 'saya', ...</td>\n",
              "      <td>['kenapa', 'aku', 'tagih', 'hutang', 'aku', 't...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>sangat bagus</td>\n",
              "      <td>sangat bagus</td>\n",
              "      <td>['sangat', 'bagus']</td>\n",
              "      <td>['sangat', 'bagus']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>bagus</td>\n",
              "      <td>bagus</td>\n",
              "      <td>['bagus']</td>\n",
              "      <td>['bagus']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>ini pengajuan pertama moga di acc krn lg butuh...</td>\n",
              "      <td>aju pertama moga acc lg butuh dana kembang war...</td>\n",
              "      <td>['aju', 'pertama', 'moga', 'acc', 'lg', 'butuh...</td>\n",
              "      <td>['aju', 'pertama', 'semoga', 'terima', 'lagi',...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17636</th>\n",
              "      <td>1</td>\n",
              "      <td>ada kami ngentod</td>\n",
              "      <td>ada kami ngentod</td>\n",
              "      <td>['ada', 'kami', 'ngentod']</td>\n",
              "      <td>['ada', 'kami', 'ngentod']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17637</th>\n",
              "      <td>1</td>\n",
              "      <td>waktu jatuh tempo masih hari tapi panggilan ma...</td>\n",
              "      <td>jatuh tempo masih hari tapi panggil masuk tagi...</td>\n",
              "      <td>['jatuh', 'tempo', 'masih', 'hari', 'tapi', 'p...</td>\n",
              "      <td>['jatuh', 'tempo', 'masih', 'hari', 'tapi', 'p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17638</th>\n",
              "      <td>1</td>\n",
              "      <td>pelayanan dan csnya buruk blum waktunya byar s...</td>\n",
              "      <td>layan csnya buruk blum waktu byar sdah tagih k...</td>\n",
              "      <td>['layan', 'csnya', 'buruk', 'blum', 'waktu', '...</td>\n",
              "      <td>['layan', 'csnya', 'buruk', 'blum', 'waktu', '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17639</th>\n",
              "      <td>1</td>\n",
              "      <td>aplikasi busuk baru daftar udah di tolak penga...</td>\n",
              "      <td>aplikasi busuk baru daftar udah tolak aju pinj...</td>\n",
              "      <td>['aplikasi', 'busuk', 'baru', 'daftar', 'udah'...</td>\n",
              "      <td>['aplikasi', 'busuk', 'baru', 'daftar', 'sudah...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17640</th>\n",
              "      <td>1</td>\n",
              "      <td>hadeh apk apaan sih ga jelas</td>\n",
              "      <td>hadeh apk apa ga jelas</td>\n",
              "      <td>['hadeh', 'apk', 'apa', 'ga', 'jelas']</td>\n",
              "      <td>['aduh', 'aplikasi', 'apa', 'tidak', 'jelas']</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>17641 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fa4176d7-e3e3-42a9-b435-f21900b815e6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fa4176d7-e3e3-42a9-b435-f21900b815e6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fa4176d7-e3e3-42a9-b435-f21900b815e6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "df_dataTraining"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJDN4Mb4jga-",
        "outputId": "15a875de-4494-4e52-a5d1-98d86438dd0e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('O')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "df_dataTraining['label'].dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YgRdMWxclBVP"
      },
      "outputs": [],
      "source": [
        "df_dataTraining['label'] = pd.to_numeric(df_dataTraining['label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srPnuHcKlIfP",
        "outputId": "7a380a9c-5006-4db9-ad28-c89556b57c72"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('float64')"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "df_dataTraining['label'].dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQi80zVUyY06",
        "outputId": "64e081e5-0b03-4042-f00a-f3cae7385a16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download(\"stopwords\")\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "20WvOoUPMwCU"
      },
      "outputs": [],
      "source": [
        "stop=set(stopwords.words(\"indonesian\"))\n",
        "stop_bow = set(stopwords.words(\"indonesian\"))\n",
        "stop_bow.discard(\"tidak\")\n",
        "factory = StemmerFactory()\n",
        "stemmer = factory.create_stemmer()\n",
        "\n",
        "text=df_dataTraining[\"normalisasi\"]\n",
        "cleaned_text_bow=[]\n",
        "cleaned_text=[]\n",
        "for line in text:\n",
        "    tags = re.compile(\"^@[a-zA-Z_]*\")\n",
        "    line = re.sub(tags,\" \",str(line))\n",
        "    hashtags = re.compile(\"#|\\*\")\n",
        "    extraCharacters = re.compile(\"[^a-zA-Z]\")\n",
        "    line = re.sub(extraCharacters,\" \",str(line))\n",
        "\n",
        "    filtered_words=[]\n",
        "    filtered_words_bow=\"\"\n",
        "    for word in line.split():\n",
        "        word=word.lower()\n",
        "        if(word not in stop):\n",
        "            word = stemmer.stem(word)\n",
        "            filtered_words.append(word)\n",
        "        if(word not in stop_bow):\n",
        "            word = stemmer.stem(word)\n",
        "            filtered_words_bow+=\" \"+word\n",
        "    cleaned_text.append(filtered_words)\n",
        "    cleaned_text_bow.append(filtered_words_bow)\n",
        "            \n",
        "data_bow = pd.DataFrame(data=cleaned_text_bow,columns=[\"Stemming\"])\n",
        "data_bow[\"label\"] = df_dataTraining[\"label\"]\n",
        "df_dataTraining[\"Stemming\"]=cleaned_text\n",
        "print(df_dataTraining.head(10))\n",
        "print()\n",
        "print(data_bow.head(10))\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KS247-QmTYfl"
      },
      "outputs": [],
      "source": [
        "# df_dataTraining.to_csv(r'drive/MyDrive/Wira/Word2Vec.csv', index = False, header = True,index_label=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XS-8Yn_SudIw"
      },
      "source": [
        "**Word Embadding (Word2vec)**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvPBytXjyrRl"
      },
      "outputs": [],
      "source": [
        "import gensim\n",
        "from tqdm import tqdm\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CfnHsopyysfb"
      },
      "outputs": [],
      "source": [
        "#Train on text data\n",
        "list_of_sent = df_dataTraining[\"Stemming\"]\n",
        "w2v_model=gensim.models.Word2Vec(list_of_sent,min_count=4,size=200, workers=4, negative=10, seed=34, ) #size = ukuran vector yg diinginkan, default cbow\n",
        "w2v_words=list(w2v_model.wv.vocab) #corpus/vocab ambil dr kata yg ada di data train \n",
        "\n",
        "# \"\"\"\n",
        "# Pertama, kode mengambil kolom \"Stemming\" dari dataframe df_dataTraining, yang berisi daftar kalimat yang telah diproses menjadi kata-kata dasar (stemmed).\n",
        "# Kemudian, model Word2Vec diinisialisasi dengan parameter min_count=4, artinya hanya kata-kata yang muncul sebanyak 4 kali atau lebih yang akan dimasukkan ke dalam kamus, size=200, \n",
        "# artinya vektor embedding yang dibuat memiliki panjang 200, workers=4, artinya pelatihan dilakukan dengan 4 thread, negative=10, artinya jumlah kata negatif yang diambil saat pelatihan adalah 10, dan seed=34, \n",
        "# artinya seed yang digunakan untuk inisialisasi model. Selanjutnya, kamus kata-kata yang ada di dalam model diambil dan disimpan dalam variabel w2v_words. \n",
        "# Kamus ini nantinya akan digunakan untuk membangun vektor representasi untuk setiap kata pada data uji dan latih.\n",
        "# \"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJm4wTuhJAtx"
      },
      "outputs": [],
      "source": [
        "df_dataTraining[\"Stemming\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SN4u3g1uy31y"
      },
      "outputs": [],
      "source": [
        "len(w2v_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Jain_bEy7Qi"
      },
      "outputs": [],
      "source": [
        "#Vectorize train text data\n",
        "listof_sent_vec=[]\n",
        "for sent in tqdm(list_of_sent): \n",
        "    sent_vec = np.zeros(200) \n",
        "    cnt_words =0; \n",
        "    for word in sent: \n",
        "        if word in w2v_words:\n",
        "            vec = w2v_model.wv[word]\n",
        "            sent_vec += vec\n",
        "            cnt_words += 1\n",
        "    if cnt_words != 0:\n",
        "        sent_vec /= cnt_words\n",
        "    listof_sent_vec.append(sent_vec)\n",
        "    \n",
        "Label = df_dataTraining[\"label\"]\n",
        "list_col=tuple(range(200))\n",
        "Scaler = StandardScaler()\n",
        "train_vec = Scaler.fit_transform(listof_sent_vec)\n",
        "W2v_df_dataTraining=pd.DataFrame(data=train_vec, columns=list_col)\n",
        "W2v_df_dataTraining[\"label\"] = Label\n",
        "\n",
        "print(W2v_df_dataTraining.head(10))\n",
        "print(W2v_df_dataTraining.shape)\n",
        "\n",
        "\n",
        "# \"\"\"\n",
        "# Proses vektorisasi dilakukan pada data training dengan mengubah setiap kalimat menjadi vektor berukuran 200 dimensi. Pada bagian pertama, list_of_sent berisi daftar kalimat yang sudah di-stemming dari data training. \n",
        "# Kemudian, model word2vec diinisialisasi dengan menggunakan parameter sebagai berikut:\n",
        "\n",
        "# min_count=4: kata yang muncul kurang dari 4 kali diabaikan dalam pembuatan vektor\n",
        "# size=200: ukuran vektor yang diinginkan\n",
        "# workers=4: jumlah thread yang digunakan untuk training\n",
        "# negative=10: jumlah kata yang dipilih sebagai negatif sampling\n",
        "# seed=34: seed untuk randomization\n",
        "\n",
        "# Setelah model word2vec dilatih, w2v_words menyimpan kumpulan kata-kata yang muncul di data training. Kemudian dilakukan iterasi pada setiap kalimat di list_of_sent. Untuk setiap kata di kalimat tersebut, \n",
        "# dicari vektor word2vec yang sesuai. Jika kata tidak ditemukan dalam w2v_words, maka kata tersebut diabaikan. Jika kata ditemukan, maka vektor word2vec-nya dijumlahkan pada sent_vec dan cnt_words ditambah 1. \n",
        "# Setelah iterasi selesai, sent_vec dibagi dengan cnt_words untuk mendapatkan rata-rata vektor kalimat tersebut. Selanjutnya, sent_vec dimasukkan ke dalam listof_sent_vec.\n",
        "# Terakhir, hasil vektorisasi tersebut disimpan ke dalam dataframe W2v_df_dataTraining. Kolom label menyimpan label dari setiap kalimat, sedangkan kolom-kolom lainnya menyimpan nilai vektor. \n",
        "# Sebelum disimpan, dilakukan normalisasi pada vektor menggunakan StandardScaler dari sklearn.preprocessing.\n",
        "\n",
        "\n",
        "# \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **LANGSUNG LOAD DATA HASIL PREPROCESSING**"
      ],
      "metadata": {
        "id": "MvIA0JI8Qyq-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKWNFliXWJzF",
        "outputId": "102f1530-f500-4413-851d-726850b6cf91"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "gTuRDKh1Q0kB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "JFaOpK92zPQ-"
      },
      "outputs": [],
      "source": [
        "W2v_df_dataTraining = pd.read_csv('drive/MyDrive/Wira/Word2Vec.csv', encoding=\"ISO-8859-1\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "W2v_df_dataTraining"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "g0Bbea26RSjS",
        "outputId": "4ae924f3-1757-4345-bff9-d4cc19f1694c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              0         1         2         3         4         5         6  \\\n",
              "0      0.589647 -0.032969  1.577858 -0.261099 -0.816928  1.169729 -0.045591   \n",
              "1      0.169849 -0.948463 -1.936053  0.370609 -0.218172  0.135423  1.503564   \n",
              "2      0.049207 -0.055259  1.162899  0.103344 -0.585705  0.272081 -0.464852   \n",
              "3      0.049207 -0.055259  1.162899  0.103344 -0.585705  0.272081 -0.464852   \n",
              "4      0.284075  0.624841  0.282875 -0.772059  0.575722  0.398152 -0.181389   \n",
              "...         ...       ...       ...       ...       ...       ...       ...   \n",
              "17635  1.421210  3.128096  0.114922 -2.611097  3.436417 -1.410561 -0.976095   \n",
              "17636 -2.929913 -1.509963 -1.346306  1.939351 -0.224151 -1.337806 -1.937517   \n",
              "17637 -0.958356 -0.204796 -0.415086  0.642472  0.206285 -0.827741 -0.794551   \n",
              "17638  0.524655 -1.013381 -2.308306  0.158416 -0.202552  0.506964  2.059501   \n",
              "17639  0.759523  0.627998 -0.269104 -0.375059  0.683213 -0.262889  0.564891   \n",
              "\n",
              "              7         8         9  ...       191       192       193  \\\n",
              "0      0.105004 -1.654137  0.374675  ... -1.184555 -0.482295 -1.474492   \n",
              "1     -0.821239  0.996892 -1.880665  ...  0.341622 -0.482107  0.355359   \n",
              "2      0.505787 -0.900250  0.626195  ... -0.431760  0.167611 -0.705386   \n",
              "3      0.505787 -0.900250  0.626195  ... -0.431760  0.167611 -0.705386   \n",
              "4     -0.392350 -0.220285  0.273051  ... -0.438284 -0.567406  0.195598   \n",
              "...         ...       ...       ...  ...       ...       ...       ...   \n",
              "17635 -1.382296  0.751334  1.908477  ...  0.470704  0.420560  1.974974   \n",
              "17636  2.330764  2.523358  0.509626  ...  2.653045  2.623997  2.299301   \n",
              "17637  0.744620  0.938180  0.443751  ...  0.945847  0.975964  0.969092   \n",
              "17638 -1.338397  1.018989 -2.423215  ...  0.114741 -0.998798  0.224538   \n",
              "17639 -0.862586  0.073697 -0.056642  ...  0.178904  0.041351  0.028916   \n",
              "\n",
              "            194       195       196       197       198       199  label  \n",
              "0      1.697958  0.375751  0.555185  0.375916  0.981808 -1.704464      2  \n",
              "1     -0.834764  0.591695 -1.615025 -1.132158  0.398693  0.635384      1  \n",
              "2      1.139312  0.352743  0.562127  0.703678  0.562917 -0.809697      2  \n",
              "3      1.139312  0.352743  0.562127  0.703678  0.562917 -0.809697      2  \n",
              "4     -0.231363 -0.827963  0.422755 -0.221953 -0.709832 -0.015067      2  \n",
              "...         ...       ...       ...       ...       ...       ...    ...  \n",
              "17635 -2.383461 -3.285148  2.407402 -1.522504 -3.361125  1.637426      1  \n",
              "17636 -1.443935  1.025284 -1.089208  2.151263 -0.149006  2.373927      1  \n",
              "17637 -0.477760  0.025019 -0.080705  0.633886 -0.314003  0.856739      1  \n",
              "17638 -0.922002  0.580955 -1.963623 -1.629168  0.435039  0.590974      1  \n",
              "17639 -0.403917 -0.590287  0.353710 -0.896975 -0.327168  0.057265      1  \n",
              "\n",
              "[17640 rows x 201 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-aded8dda-5e96-4e8c-828c-d7201de5c3c7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>191</th>\n",
              "      <th>192</th>\n",
              "      <th>193</th>\n",
              "      <th>194</th>\n",
              "      <th>195</th>\n",
              "      <th>196</th>\n",
              "      <th>197</th>\n",
              "      <th>198</th>\n",
              "      <th>199</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.589647</td>\n",
              "      <td>-0.032969</td>\n",
              "      <td>1.577858</td>\n",
              "      <td>-0.261099</td>\n",
              "      <td>-0.816928</td>\n",
              "      <td>1.169729</td>\n",
              "      <td>-0.045591</td>\n",
              "      <td>0.105004</td>\n",
              "      <td>-1.654137</td>\n",
              "      <td>0.374675</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.184555</td>\n",
              "      <td>-0.482295</td>\n",
              "      <td>-1.474492</td>\n",
              "      <td>1.697958</td>\n",
              "      <td>0.375751</td>\n",
              "      <td>0.555185</td>\n",
              "      <td>0.375916</td>\n",
              "      <td>0.981808</td>\n",
              "      <td>-1.704464</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.169849</td>\n",
              "      <td>-0.948463</td>\n",
              "      <td>-1.936053</td>\n",
              "      <td>0.370609</td>\n",
              "      <td>-0.218172</td>\n",
              "      <td>0.135423</td>\n",
              "      <td>1.503564</td>\n",
              "      <td>-0.821239</td>\n",
              "      <td>0.996892</td>\n",
              "      <td>-1.880665</td>\n",
              "      <td>...</td>\n",
              "      <td>0.341622</td>\n",
              "      <td>-0.482107</td>\n",
              "      <td>0.355359</td>\n",
              "      <td>-0.834764</td>\n",
              "      <td>0.591695</td>\n",
              "      <td>-1.615025</td>\n",
              "      <td>-1.132158</td>\n",
              "      <td>0.398693</td>\n",
              "      <td>0.635384</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.049207</td>\n",
              "      <td>-0.055259</td>\n",
              "      <td>1.162899</td>\n",
              "      <td>0.103344</td>\n",
              "      <td>-0.585705</td>\n",
              "      <td>0.272081</td>\n",
              "      <td>-0.464852</td>\n",
              "      <td>0.505787</td>\n",
              "      <td>-0.900250</td>\n",
              "      <td>0.626195</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.431760</td>\n",
              "      <td>0.167611</td>\n",
              "      <td>-0.705386</td>\n",
              "      <td>1.139312</td>\n",
              "      <td>0.352743</td>\n",
              "      <td>0.562127</td>\n",
              "      <td>0.703678</td>\n",
              "      <td>0.562917</td>\n",
              "      <td>-0.809697</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.049207</td>\n",
              "      <td>-0.055259</td>\n",
              "      <td>1.162899</td>\n",
              "      <td>0.103344</td>\n",
              "      <td>-0.585705</td>\n",
              "      <td>0.272081</td>\n",
              "      <td>-0.464852</td>\n",
              "      <td>0.505787</td>\n",
              "      <td>-0.900250</td>\n",
              "      <td>0.626195</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.431760</td>\n",
              "      <td>0.167611</td>\n",
              "      <td>-0.705386</td>\n",
              "      <td>1.139312</td>\n",
              "      <td>0.352743</td>\n",
              "      <td>0.562127</td>\n",
              "      <td>0.703678</td>\n",
              "      <td>0.562917</td>\n",
              "      <td>-0.809697</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.284075</td>\n",
              "      <td>0.624841</td>\n",
              "      <td>0.282875</td>\n",
              "      <td>-0.772059</td>\n",
              "      <td>0.575722</td>\n",
              "      <td>0.398152</td>\n",
              "      <td>-0.181389</td>\n",
              "      <td>-0.392350</td>\n",
              "      <td>-0.220285</td>\n",
              "      <td>0.273051</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.438284</td>\n",
              "      <td>-0.567406</td>\n",
              "      <td>0.195598</td>\n",
              "      <td>-0.231363</td>\n",
              "      <td>-0.827963</td>\n",
              "      <td>0.422755</td>\n",
              "      <td>-0.221953</td>\n",
              "      <td>-0.709832</td>\n",
              "      <td>-0.015067</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17635</th>\n",
              "      <td>1.421210</td>\n",
              "      <td>3.128096</td>\n",
              "      <td>0.114922</td>\n",
              "      <td>-2.611097</td>\n",
              "      <td>3.436417</td>\n",
              "      <td>-1.410561</td>\n",
              "      <td>-0.976095</td>\n",
              "      <td>-1.382296</td>\n",
              "      <td>0.751334</td>\n",
              "      <td>1.908477</td>\n",
              "      <td>...</td>\n",
              "      <td>0.470704</td>\n",
              "      <td>0.420560</td>\n",
              "      <td>1.974974</td>\n",
              "      <td>-2.383461</td>\n",
              "      <td>-3.285148</td>\n",
              "      <td>2.407402</td>\n",
              "      <td>-1.522504</td>\n",
              "      <td>-3.361125</td>\n",
              "      <td>1.637426</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17636</th>\n",
              "      <td>-2.929913</td>\n",
              "      <td>-1.509963</td>\n",
              "      <td>-1.346306</td>\n",
              "      <td>1.939351</td>\n",
              "      <td>-0.224151</td>\n",
              "      <td>-1.337806</td>\n",
              "      <td>-1.937517</td>\n",
              "      <td>2.330764</td>\n",
              "      <td>2.523358</td>\n",
              "      <td>0.509626</td>\n",
              "      <td>...</td>\n",
              "      <td>2.653045</td>\n",
              "      <td>2.623997</td>\n",
              "      <td>2.299301</td>\n",
              "      <td>-1.443935</td>\n",
              "      <td>1.025284</td>\n",
              "      <td>-1.089208</td>\n",
              "      <td>2.151263</td>\n",
              "      <td>-0.149006</td>\n",
              "      <td>2.373927</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17637</th>\n",
              "      <td>-0.958356</td>\n",
              "      <td>-0.204796</td>\n",
              "      <td>-0.415086</td>\n",
              "      <td>0.642472</td>\n",
              "      <td>0.206285</td>\n",
              "      <td>-0.827741</td>\n",
              "      <td>-0.794551</td>\n",
              "      <td>0.744620</td>\n",
              "      <td>0.938180</td>\n",
              "      <td>0.443751</td>\n",
              "      <td>...</td>\n",
              "      <td>0.945847</td>\n",
              "      <td>0.975964</td>\n",
              "      <td>0.969092</td>\n",
              "      <td>-0.477760</td>\n",
              "      <td>0.025019</td>\n",
              "      <td>-0.080705</td>\n",
              "      <td>0.633886</td>\n",
              "      <td>-0.314003</td>\n",
              "      <td>0.856739</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17638</th>\n",
              "      <td>0.524655</td>\n",
              "      <td>-1.013381</td>\n",
              "      <td>-2.308306</td>\n",
              "      <td>0.158416</td>\n",
              "      <td>-0.202552</td>\n",
              "      <td>0.506964</td>\n",
              "      <td>2.059501</td>\n",
              "      <td>-1.338397</td>\n",
              "      <td>1.018989</td>\n",
              "      <td>-2.423215</td>\n",
              "      <td>...</td>\n",
              "      <td>0.114741</td>\n",
              "      <td>-0.998798</td>\n",
              "      <td>0.224538</td>\n",
              "      <td>-0.922002</td>\n",
              "      <td>0.580955</td>\n",
              "      <td>-1.963623</td>\n",
              "      <td>-1.629168</td>\n",
              "      <td>0.435039</td>\n",
              "      <td>0.590974</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17639</th>\n",
              "      <td>0.759523</td>\n",
              "      <td>0.627998</td>\n",
              "      <td>-0.269104</td>\n",
              "      <td>-0.375059</td>\n",
              "      <td>0.683213</td>\n",
              "      <td>-0.262889</td>\n",
              "      <td>0.564891</td>\n",
              "      <td>-0.862586</td>\n",
              "      <td>0.073697</td>\n",
              "      <td>-0.056642</td>\n",
              "      <td>...</td>\n",
              "      <td>0.178904</td>\n",
              "      <td>0.041351</td>\n",
              "      <td>0.028916</td>\n",
              "      <td>-0.403917</td>\n",
              "      <td>-0.590287</td>\n",
              "      <td>0.353710</td>\n",
              "      <td>-0.896975</td>\n",
              "      <td>-0.327168</td>\n",
              "      <td>0.057265</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>17640 rows × 201 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aded8dda-5e96-4e8c-828c-d7201de5c3c7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-aded8dda-5e96-4e8c-828c-d7201de5c3c7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-aded8dda-5e96-4e8c-828c-d7201de5c3c7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "IOFz72Cgzt8J",
        "outputId": "a457d523-0dcf-45c6-e140-0bd6cccb67ff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              0         1         2         3         4         5         6  \\\n",
              "0      0.589647 -0.032969  1.577858 -0.261099 -0.816928  1.169729 -0.045591   \n",
              "1      0.169849 -0.948463 -1.936053  0.370609 -0.218172  0.135423  1.503564   \n",
              "2      0.049207 -0.055259  1.162899  0.103344 -0.585705  0.272081 -0.464852   \n",
              "3      0.049207 -0.055259  1.162899  0.103344 -0.585705  0.272081 -0.464852   \n",
              "4      0.284075  0.624841  0.282875 -0.772059  0.575722  0.398152 -0.181389   \n",
              "...         ...       ...       ...       ...       ...       ...       ...   \n",
              "17635  1.421210  3.128096  0.114922 -2.611097  3.436417 -1.410561 -0.976095   \n",
              "17636 -2.929913 -1.509963 -1.346306  1.939351 -0.224151 -1.337806 -1.937517   \n",
              "17637 -0.958356 -0.204796 -0.415086  0.642472  0.206285 -0.827741 -0.794551   \n",
              "17638  0.524655 -1.013381 -2.308306  0.158416 -0.202552  0.506964  2.059501   \n",
              "17639  0.759523  0.627998 -0.269104 -0.375059  0.683213 -0.262889  0.564891   \n",
              "\n",
              "              7         8         9  ...       191       192       193  \\\n",
              "0      0.105004 -1.654137  0.374675  ... -1.184555 -0.482295 -1.474492   \n",
              "1     -0.821239  0.996892 -1.880665  ...  0.341622 -0.482107  0.355359   \n",
              "2      0.505787 -0.900250  0.626195  ... -0.431760  0.167611 -0.705386   \n",
              "3      0.505787 -0.900250  0.626195  ... -0.431760  0.167611 -0.705386   \n",
              "4     -0.392350 -0.220285  0.273051  ... -0.438284 -0.567406  0.195598   \n",
              "...         ...       ...       ...  ...       ...       ...       ...   \n",
              "17635 -1.382296  0.751334  1.908477  ...  0.470704  0.420560  1.974974   \n",
              "17636  2.330764  2.523358  0.509626  ...  2.653045  2.623997  2.299301   \n",
              "17637  0.744620  0.938180  0.443751  ...  0.945847  0.975964  0.969092   \n",
              "17638 -1.338397  1.018989 -2.423215  ...  0.114741 -0.998798  0.224538   \n",
              "17639 -0.862586  0.073697 -0.056642  ...  0.178904  0.041351  0.028916   \n",
              "\n",
              "            194       195       196       197       198       199  label  \n",
              "0      1.697958  0.375751  0.555185  0.375916  0.981808 -1.704464      2  \n",
              "1     -0.834764  0.591695 -1.615025 -1.132158  0.398693  0.635384      1  \n",
              "2      1.139312  0.352743  0.562127  0.703678  0.562917 -0.809697      2  \n",
              "3      1.139312  0.352743  0.562127  0.703678  0.562917 -0.809697      2  \n",
              "4     -0.231363 -0.827963  0.422755 -0.221953 -0.709832 -0.015067      2  \n",
              "...         ...       ...       ...       ...       ...       ...    ...  \n",
              "17635 -2.383461 -3.285148  2.407402 -1.522504 -3.361125  1.637426      1  \n",
              "17636 -1.443935  1.025284 -1.089208  2.151263 -0.149006  2.373927      1  \n",
              "17637 -0.477760  0.025019 -0.080705  0.633886 -0.314003  0.856739      1  \n",
              "17638 -0.922002  0.580955 -1.963623 -1.629168  0.435039  0.590974      1  \n",
              "17639 -0.403917 -0.590287  0.353710 -0.896975 -0.327168  0.057265      1  \n",
              "\n",
              "[17640 rows x 201 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e9c7364e-1403-4f73-8036-6d3ab446a9db\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>191</th>\n",
              "      <th>192</th>\n",
              "      <th>193</th>\n",
              "      <th>194</th>\n",
              "      <th>195</th>\n",
              "      <th>196</th>\n",
              "      <th>197</th>\n",
              "      <th>198</th>\n",
              "      <th>199</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.589647</td>\n",
              "      <td>-0.032969</td>\n",
              "      <td>1.577858</td>\n",
              "      <td>-0.261099</td>\n",
              "      <td>-0.816928</td>\n",
              "      <td>1.169729</td>\n",
              "      <td>-0.045591</td>\n",
              "      <td>0.105004</td>\n",
              "      <td>-1.654137</td>\n",
              "      <td>0.374675</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.184555</td>\n",
              "      <td>-0.482295</td>\n",
              "      <td>-1.474492</td>\n",
              "      <td>1.697958</td>\n",
              "      <td>0.375751</td>\n",
              "      <td>0.555185</td>\n",
              "      <td>0.375916</td>\n",
              "      <td>0.981808</td>\n",
              "      <td>-1.704464</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.169849</td>\n",
              "      <td>-0.948463</td>\n",
              "      <td>-1.936053</td>\n",
              "      <td>0.370609</td>\n",
              "      <td>-0.218172</td>\n",
              "      <td>0.135423</td>\n",
              "      <td>1.503564</td>\n",
              "      <td>-0.821239</td>\n",
              "      <td>0.996892</td>\n",
              "      <td>-1.880665</td>\n",
              "      <td>...</td>\n",
              "      <td>0.341622</td>\n",
              "      <td>-0.482107</td>\n",
              "      <td>0.355359</td>\n",
              "      <td>-0.834764</td>\n",
              "      <td>0.591695</td>\n",
              "      <td>-1.615025</td>\n",
              "      <td>-1.132158</td>\n",
              "      <td>0.398693</td>\n",
              "      <td>0.635384</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.049207</td>\n",
              "      <td>-0.055259</td>\n",
              "      <td>1.162899</td>\n",
              "      <td>0.103344</td>\n",
              "      <td>-0.585705</td>\n",
              "      <td>0.272081</td>\n",
              "      <td>-0.464852</td>\n",
              "      <td>0.505787</td>\n",
              "      <td>-0.900250</td>\n",
              "      <td>0.626195</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.431760</td>\n",
              "      <td>0.167611</td>\n",
              "      <td>-0.705386</td>\n",
              "      <td>1.139312</td>\n",
              "      <td>0.352743</td>\n",
              "      <td>0.562127</td>\n",
              "      <td>0.703678</td>\n",
              "      <td>0.562917</td>\n",
              "      <td>-0.809697</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.049207</td>\n",
              "      <td>-0.055259</td>\n",
              "      <td>1.162899</td>\n",
              "      <td>0.103344</td>\n",
              "      <td>-0.585705</td>\n",
              "      <td>0.272081</td>\n",
              "      <td>-0.464852</td>\n",
              "      <td>0.505787</td>\n",
              "      <td>-0.900250</td>\n",
              "      <td>0.626195</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.431760</td>\n",
              "      <td>0.167611</td>\n",
              "      <td>-0.705386</td>\n",
              "      <td>1.139312</td>\n",
              "      <td>0.352743</td>\n",
              "      <td>0.562127</td>\n",
              "      <td>0.703678</td>\n",
              "      <td>0.562917</td>\n",
              "      <td>-0.809697</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.284075</td>\n",
              "      <td>0.624841</td>\n",
              "      <td>0.282875</td>\n",
              "      <td>-0.772059</td>\n",
              "      <td>0.575722</td>\n",
              "      <td>0.398152</td>\n",
              "      <td>-0.181389</td>\n",
              "      <td>-0.392350</td>\n",
              "      <td>-0.220285</td>\n",
              "      <td>0.273051</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.438284</td>\n",
              "      <td>-0.567406</td>\n",
              "      <td>0.195598</td>\n",
              "      <td>-0.231363</td>\n",
              "      <td>-0.827963</td>\n",
              "      <td>0.422755</td>\n",
              "      <td>-0.221953</td>\n",
              "      <td>-0.709832</td>\n",
              "      <td>-0.015067</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17635</th>\n",
              "      <td>1.421210</td>\n",
              "      <td>3.128096</td>\n",
              "      <td>0.114922</td>\n",
              "      <td>-2.611097</td>\n",
              "      <td>3.436417</td>\n",
              "      <td>-1.410561</td>\n",
              "      <td>-0.976095</td>\n",
              "      <td>-1.382296</td>\n",
              "      <td>0.751334</td>\n",
              "      <td>1.908477</td>\n",
              "      <td>...</td>\n",
              "      <td>0.470704</td>\n",
              "      <td>0.420560</td>\n",
              "      <td>1.974974</td>\n",
              "      <td>-2.383461</td>\n",
              "      <td>-3.285148</td>\n",
              "      <td>2.407402</td>\n",
              "      <td>-1.522504</td>\n",
              "      <td>-3.361125</td>\n",
              "      <td>1.637426</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17636</th>\n",
              "      <td>-2.929913</td>\n",
              "      <td>-1.509963</td>\n",
              "      <td>-1.346306</td>\n",
              "      <td>1.939351</td>\n",
              "      <td>-0.224151</td>\n",
              "      <td>-1.337806</td>\n",
              "      <td>-1.937517</td>\n",
              "      <td>2.330764</td>\n",
              "      <td>2.523358</td>\n",
              "      <td>0.509626</td>\n",
              "      <td>...</td>\n",
              "      <td>2.653045</td>\n",
              "      <td>2.623997</td>\n",
              "      <td>2.299301</td>\n",
              "      <td>-1.443935</td>\n",
              "      <td>1.025284</td>\n",
              "      <td>-1.089208</td>\n",
              "      <td>2.151263</td>\n",
              "      <td>-0.149006</td>\n",
              "      <td>2.373927</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17637</th>\n",
              "      <td>-0.958356</td>\n",
              "      <td>-0.204796</td>\n",
              "      <td>-0.415086</td>\n",
              "      <td>0.642472</td>\n",
              "      <td>0.206285</td>\n",
              "      <td>-0.827741</td>\n",
              "      <td>-0.794551</td>\n",
              "      <td>0.744620</td>\n",
              "      <td>0.938180</td>\n",
              "      <td>0.443751</td>\n",
              "      <td>...</td>\n",
              "      <td>0.945847</td>\n",
              "      <td>0.975964</td>\n",
              "      <td>0.969092</td>\n",
              "      <td>-0.477760</td>\n",
              "      <td>0.025019</td>\n",
              "      <td>-0.080705</td>\n",
              "      <td>0.633886</td>\n",
              "      <td>-0.314003</td>\n",
              "      <td>0.856739</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17638</th>\n",
              "      <td>0.524655</td>\n",
              "      <td>-1.013381</td>\n",
              "      <td>-2.308306</td>\n",
              "      <td>0.158416</td>\n",
              "      <td>-0.202552</td>\n",
              "      <td>0.506964</td>\n",
              "      <td>2.059501</td>\n",
              "      <td>-1.338397</td>\n",
              "      <td>1.018989</td>\n",
              "      <td>-2.423215</td>\n",
              "      <td>...</td>\n",
              "      <td>0.114741</td>\n",
              "      <td>-0.998798</td>\n",
              "      <td>0.224538</td>\n",
              "      <td>-0.922002</td>\n",
              "      <td>0.580955</td>\n",
              "      <td>-1.963623</td>\n",
              "      <td>-1.629168</td>\n",
              "      <td>0.435039</td>\n",
              "      <td>0.590974</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17639</th>\n",
              "      <td>0.759523</td>\n",
              "      <td>0.627998</td>\n",
              "      <td>-0.269104</td>\n",
              "      <td>-0.375059</td>\n",
              "      <td>0.683213</td>\n",
              "      <td>-0.262889</td>\n",
              "      <td>0.564891</td>\n",
              "      <td>-0.862586</td>\n",
              "      <td>0.073697</td>\n",
              "      <td>-0.056642</td>\n",
              "      <td>...</td>\n",
              "      <td>0.178904</td>\n",
              "      <td>0.041351</td>\n",
              "      <td>0.028916</td>\n",
              "      <td>-0.403917</td>\n",
              "      <td>-0.590287</td>\n",
              "      <td>0.353710</td>\n",
              "      <td>-0.896975</td>\n",
              "      <td>-0.327168</td>\n",
              "      <td>0.057265</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>17640 rows × 201 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e9c7364e-1403-4f73-8036-6d3ab446a9db')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e9c7364e-1403-4f73-8036-6d3ab446a9db button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e9c7364e-1403-4f73-8036-6d3ab446a9db');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "def clean_dataset(df):\n",
        "    assert isinstance(df, pd.DataFrame), \"df needs to be a pd.DataFrame\"\n",
        "    df.dropna(inplace=True)\n",
        "    indices_to_keep = ~df.isin([np.nan, np.inf, -np.inf]).any(1)\n",
        "    return df[indices_to_keep].astype(np.float64)\n",
        "\n",
        "clean_dataset(W2v_df_dataTraining)\n",
        "W2v_df_dataTraining"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLF9FU_Ezdl5",
        "outputId": "79fdea97-d30d-41dd-b96c-3c5f39ad8369"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.5896474 , -0.0329686 ,  1.57785791, ...,  0.37591602,\n",
              "         0.98180843, -1.70446447],\n",
              "       [ 0.16984885, -0.94846334, -1.93605267, ..., -1.13215766,\n",
              "         0.39869305,  0.635384  ],\n",
              "       [ 0.04920737, -0.05525941,  1.16289923, ...,  0.70367819,\n",
              "         0.56291684, -0.80969728],\n",
              "       ...,\n",
              "       [-0.95835596, -0.2047959 , -0.41508558, ...,  0.63388551,\n",
              "        -0.31400326,  0.85673897],\n",
              "       [ 0.5246552 , -1.01338077, -2.30830572, ..., -1.62916827,\n",
              "         0.43503892,  0.59097428],\n",
              "       [ 0.75952328,  0.62799785, -0.26910375, ..., -0.89697514,\n",
              "        -0.32716766,  0.057265  ]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "X = W2v_df_dataTraining.drop(\"label\",axis=1).to_numpy()\n",
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ZJn8W3dtCDmh"
      },
      "outputs": [],
      "source": [
        "y = W2v_df_dataTraining['label'].to_numpy()\n",
        "X = W2v_df_dataTraining.drop(\"label\",axis=1).to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "PTV3AdcX0uHR"
      },
      "outputs": [],
      "source": [
        "W2v_df_dataTraining['label'] = pd.to_numeric(W2v_df_dataTraining['label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bj6DfTMsz7jA",
        "outputId": "106a1985-ee3d-4460-c52b-15f5a8342b31"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 1, 2, 2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "y = W2v_df_dataTraining[\"label\"].to_numpy()\n",
        "y[0:5]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# W2v_df_dataTraining.to_csv(r'drive/MyDrive/Wira/Word2Vec.csv', index = False, header = True,index_label=None)"
      ],
      "metadata": {
        "id": "34gqCMJ5-NGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "z32XsB8sNOCP"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size = 0.2, stratify=y, random_state=30)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxmuAAPyzETH",
        "outputId": "9e9a0d6d-7dee-489f-bf75-38d6749f6fe5"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(14112, 200)\n",
            "(14112,)\n",
            "(3528, 200)\n",
            "(3528,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import tree\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree, export_graphviz\n",
        "from sklearn import metrics\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "import pyswarms as ps\n",
        "rf = RandomForestClassifier()"
      ],
      "metadata": {
        "id": "3nU2JWS9cwU7"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Membuat objek model RF\n",
        "rf = RandomForestClassifier(n_estimators=200, max_depth=13, criterion='entropy')\n",
        "\n",
        "# Melakukan pelatihan model RF\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Membuat objek model XGBoost\n",
        "xgb = XGBClassifier(max_depth=6, n_estimators=200, learning_rate=0.05)\n",
        "\n",
        "# Melakukan pelatihan model XGBoost\n",
        "xgb.fit(X_train, y_train)\n",
        "\n",
        "# Membuat objek model SVM\n",
        "svm = SVC(kernel='rbf', probability=True)\n",
        "\n",
        "# Melakukan pelatihan model SVM\n",
        "svm.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "aLdYEQUmhA9W",
        "outputId": "2ce3df33-f264-45ac-f7c7-98bbd3367f81"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(probability=True)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(probability=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(probability=True)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fungsi objektif untuk optimisasi PSO\n",
        "def objective_function(weights, X_train, y_train, X_test, y_test):\n",
        "    # Melakukan prediksi probabilitas menggunakan masing-masing model dan bobot\n",
        "    ensemble = (weights[0] * rf.predict_proba(X_train) + weights[1] * xgb.predict_proba(X_train) + weights[2] * svm.predict_proba(X_train))\n",
        "    # Menghitung akurasi menggunakan bobot\n",
        "    y_pred = np.argmax(ensemble, axis=1)\n",
        "    accuracy = accuracy_score(y_train, y_pred)\n",
        "    # Mengembalikan nilai negatif akurasi untuk optimisasi maksimum\n",
        "    return -accuracy\n",
        "\n",
        "# Membuat objek optimizer PSO\n",
        "options = {'c1': 0.5, 'c2': 0.3, 'w': 0.9}\n",
        "optimizer = ps.single.GlobalBestPSO(n_particles=10, dimensions=3, options=options)\n",
        "\n",
        "# Melakukan optimisasi PSO untuk mendapatkan bobot terbaik\n",
        "best_cost, best_weights = optimizer.optimize(objective_function, iters=50, X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test)\n",
        "\n",
        "# Menampilkan bobot terbaik dan akurasi model dengan bobot tersebut\n",
        "print(\"Bobot terbaik:\", best_weights)\n",
        "ensemble = (best_weights[0] * rf.predict_proba(X_test) + best_weights[1] * xgb.predict_proba(X_test) + best_weights[2] * svm.predict_proba(X_test))\n",
        "y_pred = np.argmax(ensemble, axis=1)\n",
        "print(\"Akurasi dengan bobot terbaik:\", accuracy_score(y_test, y_pred))\n",
        "\n",
        "# Implementasi bobot ke model soft voting\n",
        "ensemble = (best_weights[0] * rf.predict_proba(X_test) + best_weights[1] * xgb.predict_proba(X_test) + best_weights[2] * svm.predict_proba(X_test))\n",
        "y_pred = np.argmax(ensemble, axis=1)\n",
        "print(\"Akurasi soft voting dengan bobot terbaik:\", accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yl9DtJN7hIrj",
        "outputId": "d7ba8df2-f4a3-4962-feb5-f247f8b25e27"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2023-03-12 16:13:25,040 - pyswarms.single.global_best - INFO - Optimize for 50 iters with {'c1': 0.5, 'c2': 0.3, 'w': 0.9}\n",
            "pyswarms.single.global_best: 100%|██████████|50/50, best_cost=-.866\n",
            "2023-03-12 16:35:55,269 - pyswarms.single.global_best - INFO - Optimization finished | best cost: -0.8664965986394558, best pos: [2.30158029 1.10114021 0.31199838]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bobot terbaik: [2.30158029 1.10114021 0.31199838]\n",
            "Akurasi dengan bobot terbaik: 0.8089569160997733\n",
            "Akurasi soft voting dengan bobot terbaik: 0.8089569160997733\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(\"Soft Voting Accuracy: \", accuracy_score(y_test, y_pred))\n",
        "print(\"Soft Voting Precision: \", precision_score(y_test, y_pred,  average='weighted'))\n",
        "print(\"Soft Voting Recall: \", recall_score(y_test, y_pred, average='weighted'))\n",
        "print(\"Soft Votingt f1_score: \", f1_score(y_test, y_pred, average='weighted'))\n",
        "print (classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXASNpTrYwqm",
        "outputId": "d1107b75-9b78-4c4a-95fb-c094528737f1"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Soft Voting Accuracy:  0.8089569160997733\n",
            "Soft Voting Precision:  0.7953298584585894\n",
            "Soft Voting Recall:  0.8089569160997733\n",
            "Soft Votingt f1_score:  0.7933823720596428\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.27      0.38       424\n",
            "           1       0.84      0.88      0.86      1547\n",
            "           2       0.80      0.88      0.84      1557\n",
            "\n",
            "    accuracy                           0.81      3528\n",
            "   macro avg       0.75      0.68      0.69      3528\n",
            "weighted avg       0.80      0.81      0.79      3528\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GeHCF5Ky93x"
      },
      "source": [
        "# **RANDOM** **FOREST**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Mpl8XCZZOMS"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "class RandomForestClassifier:\n",
        "    def __init__(self, n_estimators=100, max_depth=None, min_samples_split=2, random_state=None):\n",
        "        self.n_estimators = n_estimators\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.random_state = random_state\n",
        "        self.trees = []\n",
        "    \n",
        "    def fit(self, X, y):\n",
        "        np.random.seed(self.random_state)\n",
        "        for i in range(self.n_estimators):\n",
        "            # bootstrap sample\n",
        "            idx = np.random.choice(X.shape[0], size=X.shape[0], replace=True)\n",
        "            X_boot, y_boot = X[idx], y[idx]\n",
        "            \n",
        "            # train decision tree\n",
        "            dt = DecisionTreeClassifier(max_depth=self.max_depth, min_samples_split=self.min_samples_split)\n",
        "            dt.fit(X_boot, y_boot)\n",
        "            \n",
        "            # save tree\n",
        "            self.trees.append(dt)\n",
        "    \n",
        "    def predict(self, X):\n",
        "        # make predictions for each tree\n",
        "        predictions = np.array([tree.predict(X) for tree in self.trees])\n",
        "        # calculate mode (most frequent class) for each sample\n",
        "        return np.apply_along_axis(lambda x: Counter(x).most_common(1)[0][0], axis=0, arr=predictions)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = RandomForestClassifier(n_estimators=200, max_depth=13, min_samples_split=2, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "acc = np.mean(y_pred == y_test)\n",
        "print(\"Accuracy:\", acc)"
      ],
      "metadata": {
        "id": "kuAX3qhS776W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n0nNECYFZQyl"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(\"Random Forest Accuracy: \", accuracy_score(y_test, y_pred))\n",
        "print(\"Random Forest Precision: \", precision_score(y_test, y_pred,  average='weighted'))\n",
        "print(\"Random Forest Recall: \", recall_score(y_test, y_pred, average='weighted'))\n",
        "print(\"Random Forest f1_score: \", f1_score(y_test, y_pred, average='weighted'))\n",
        "print (classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "confusion_matrix(y_test, y_pred)\n",
        "\n",
        "fig, ax = plt.subplots(figsize = (8,6))\n",
        "sns.heatmap(confusion_matrix(y_true = y_test, y_pred = y_pred), fmt = 'g', annot = True)\n",
        "ax.xaxis.set_label_position('top')\n",
        "ax.xaxis.set_ticks_position('top')\n",
        "ax.set_xlabel('Prediction', fontsize = 14)\n",
        "ax.set_xticklabels([ 'neutral (1)','negative (0)', 'positive (-1)' ])\n",
        "ax.set_ylabel('Actual', fontsize = 14)\n",
        "ax.set_yticklabels([ 'neutral (1)','negative (0)', 'positive (-1)'] )\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-5eWQG4xsFuv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJULK14jzBwb"
      },
      "source": [
        "# **XGBOOST**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ARUEwDeBGRQV"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "\n",
        "class XGBoost:\n",
        "    def __init__(self, n_trees=100, learning_rate=0.5, max_depth=13, reg_alpha=0, reg_lambda=0):\n",
        "        self.n_trees = n_trees\n",
        "        self.learning_rate = learning_rate\n",
        "        self.max_depth = max_depth\n",
        "        self.reg_alpha = reg_alpha\n",
        "        self.reg_lambda = reg_lambda\n",
        "        self.trees = []\n",
        "        self.f0 = None\n",
        "        \n",
        "    def fit(self, X, y):\n",
        "        # Normalize the input features\n",
        "        X = (X - X.mean(axis=0)) / X.std(axis=0)\n",
        "\n",
        "        # Round the target labels to integer values\n",
        "        y = np.round(y)\n",
        "\n",
        "        # Convert y to integer type\n",
        "        y = y.astype(int)\n",
        "\n",
        "        # Convert y to one-hot encoding\n",
        "        y_onehot = np.zeros((y.shape[0], np.max(y) + 1))\n",
        "        y_onehot[np.arange(y.shape[0]), y] = 1\n",
        "        \n",
        "        # Initialize the model\n",
        "        self.f0 = np.mean(y_onehot, axis=0)\n",
        "        pred = np.full((X.shape[0], y_onehot.shape[1]), self.f0)\n",
        "        \n",
        "        for i in range(self.n_trees):\n",
        "            # Compute the gradients of the loss function with respect to the predictions\n",
        "            grad = y_onehot - pred\n",
        "            trees = []\n",
        "            for j in range(y_onehot.shape[1]):\n",
        "                # Compute the gradients of the loss function with respect to the outputs of the previous trees for each class\n",
        "                grad_prev = grad[:, j] - self.reg_alpha * np.sign(pred[:, j]) - self.reg_lambda * pred[:, j]\n",
        "\n",
        "                # Fit a new tree to the gradients of the current class\n",
        "                tree = DecisionTreeRegressor(max_depth=self.max_depth)\n",
        "                tree.fit(X, grad_prev)\n",
        "\n",
        "                # Add the new tree to the model for each class\n",
        "                trees.append(tree)\n",
        "\n",
        "                # Update the predictions for the current class\n",
        "                pred[:, j] += self.learning_rate * tree.predict(X)\n",
        "\n",
        "            self.trees.append(trees)\n",
        "            \n",
        "    def predict_proba(self, X):\n",
        "        # Initialize the predictions\n",
        "        pred = np.full((X.shape[0], self.f0.shape[0]), self.f0)\n",
        "\n",
        "        # Compute the predictions by summing the outputs of each tree for each class\n",
        "        for i in range(self.n_trees):\n",
        "            for j in range(len(self.trees[i])):\n",
        "                pred[:, j] += self.learning_rate * self.trees[i][j].predict(X)\n",
        "\n",
        "        # Apply the softmax function to get the class probabilities\n",
        "        pred = np.exp(pred - np.max(pred, axis=1, keepdims=True))\n",
        "        return pred / np.sum(pred, axis=1, keepdims=True)\n",
        "    \n",
        "    def predict(self, X):\n",
        "        # Predict the class with the highest probability\n",
        "        return np.argmax(self.predict_proba(X), axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P8BqyJQ_GTEa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6250a306-65d6-456d-d2f0-65b76059739b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8072562358276644\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "# Initialize the XGBoost model\n",
        "xgb = XGBoost(n_trees=100, learning_rate=0.5, max_depth=3, reg_alpha=0, reg_lambda=0)\n",
        "\n",
        "# Fit the model on the training set\n",
        "xgb.fit(X_train, y_train)\n",
        "\n",
        "# Predict the classes for the testing set\n",
        "y_pred = xgb.predict(X_test)\n",
        "\n",
        "# Compute the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUa7JOwWGUxD",
        "outputId": "c416e214-441e-42b8-e5c6-a37f343364c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost Accuracy: 0.8072562358276644\n",
            "XGBoost Precision: 0.7947523366706448\n",
            "XGBoost Recall: 0.6836832808858112\n",
            "XGBoost F1-score: 0.7935413799777414\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.30      0.40       424\n",
            "           1       0.84      0.88      0.86      1547\n",
            "           2       0.80      0.87      0.84      1557\n",
            "\n",
            "    accuracy                           0.81      3528\n",
            "   macro avg       0.75      0.68      0.70      3528\n",
            "weighted avg       0.79      0.81      0.79      3528\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Evaluasi performa model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='macro')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print('XGBoost Accuracy:', accuracy)\n",
        "print('XGBoost Precision:', precision)\n",
        "print('XGBoost Recall:', recall)\n",
        "print('XGBoost F1-score:', f1)\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(y_test, y_pred)\n",
        "\n",
        "fig, ax = plt.subplots(figsize = (8,6))\n",
        "sns.heatmap(confusion_matrix(y_true = y_test, y_pred = y_pred), fmt = 'g', annot = True)\n",
        "ax.xaxis.set_label_position('top')\n",
        "ax.xaxis.set_ticks_position('top')\n",
        "ax.set_xlabel('Prediction', fontsize = 14)\n",
        "ax.set_xticklabels([ 'neutral (1)','negative (0)', 'positive (-1)' ])\n",
        "ax.set_ylabel('Actual', fontsize = 14)\n",
        "ax.set_yticklabels([ 'neutral (1)','negative (0)', 'positive (-1)'] )\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "Ni3PecqZs0OV",
        "outputId": "a53d6cb1-f4d2-4ea2-bec7-5c77148cfbbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x432 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vaY9VqEDzHCi"
      },
      "source": [
        "# **SVM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Z_mkq8eM0TW"
      },
      "outputs": [],
      "source": [
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from sklearn.utils import check_random_state\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X77PqcWqMQqK"
      },
      "outputs": [],
      "source": [
        "def projection_simplex(v, z=1):\n",
        "    \"\"\"\n",
        "    Projection onto the simplex:\n",
        "        w^* = argmin_w 0.5 ||w-v||^2 s.t. \\sum_i w_i = z, w_i >= 0\n",
        "    \"\"\"\n",
        "    n_features = v.shape[0]\n",
        "    u = np.sort(v)[::-1]\n",
        "    cssv = np.cumsum(u) - z\n",
        "    ind = np.arange(n_features) + 1\n",
        "    cond = u - cssv / ind > 0\n",
        "    rho = ind[cond][-1]\n",
        "    theta = cssv[cond][-1] / float(rho)\n",
        "    w = np.maximum(v - theta, 0)\n",
        "    return w"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gYTpX7oL1DbZ"
      },
      "outputs": [],
      "source": [
        "class MulticlassSVM(BaseEstimator, ClassifierMixin):\n",
        "    def __init__(self, C=1, max_iter=50, tol=0.05, kernel='linear',\n",
        "                 random_state=None, verbose=0):\n",
        "        self.C = C\n",
        "        self.max_iter = max_iter\n",
        "        self.tol = tol,\n",
        "        self.kernel = kernel\n",
        "        self.random_state = random_state\n",
        "        self.verbose = verbose\n",
        "    def _partial_gradient(self, X, y, i):\n",
        "        # Partial gradient for the ith sample.\n",
        "        if self.kernel == 'linear':\n",
        "            g = np.dot(X[i], self.coef_.T) + 1\n",
        "        elif self.kernel == 'rbf':\n",
        "            # compute RBF kernel\n",
        "            K = np.exp(-self.gamma * np.sum((X - X[i])**2, axis=1))\n",
        "            g = np.dot(K, self.dual_coef_.T) + 1\n",
        "        g[y[i]] -= 1\n",
        "        return g\n",
        "    def _violation(self, g, y, i):\n",
        "        # Optimality violation for the ith sample.\n",
        "        smallest = np.inf\n",
        "        for k in range(g.shape[0]):\n",
        "            if k == y[i] and self.dual_coef_[k, i] >= self.C:\n",
        "                continue\n",
        "            elif k != y[i] and self.dual_coef_[k, i] >= 0:\n",
        "                continue\n",
        "            smallest = min(smallest, g[k])\n",
        "        return g.max() - smallest\n",
        "    def _solve_subproblem(self, g, y, norms, i):\n",
        "        # Prepare inputs to the projection.\n",
        "        Ci = np.zeros(g.shape[0])\n",
        "        Ci[y[i]] = self.C\n",
        "        beta_hat = norms[i] * (Ci - self.dual_coef_[:, i]) + g / norms[i]\n",
        "        z = self.C * norms[i]\n",
        "        # Compute projection onto the simplex.\n",
        "        beta = projection_simplex(beta_hat, z)\n",
        "        return Ci - self.dual_coef_[:, i] - beta / norms[i]\n",
        "    def fit(self, X, y):\n",
        "        n_samples, n_features = X.shape\n",
        "        # Normalize labels.\n",
        "        self._label_encoder = LabelEncoder()\n",
        "        y = self._label_encoder.fit_transform(y)\n",
        "        # Initialize primal and dual coefficients.\n",
        "        n_classes = len(self._label_encoder.classes_)\n",
        "        self.dual_coef_ = np.zeros((n_classes, n_samples), dtype=np.float64)\n",
        "        self.coef_ = np.zeros((n_classes, n_features))\n",
        "        # Pre-compute norms.\n",
        "        norms = np.sqrt(np.sum(X ** 2, axis=1))\n",
        "        # Shuffle sample indices.\n",
        "        rs = check_random_state(self.random_state)\n",
        "        ind = np.arange(n_samples)\n",
        "        rs.shuffle(ind)\n",
        "        violation_init = None\n",
        "        for it in range(self.max_iter):\n",
        "            violation_sum = 0\n",
        "            for ii in range(n_samples):\n",
        "                i = ind[ii]\n",
        "                # All-zero samples can be safely ignored.\n",
        "                if norms[i] == 0:\n",
        "                    continue\n",
        "                g = self._partial_gradient(X, y, i)\n",
        "                v = self._violation(g, y, i)\n",
        "                violation_sum += v\n",
        "                if v < 1e-12:\n",
        "                    continue\n",
        "                delta = self._solve_subproblem(g, y, norms, i)\n",
        "                self.coef_ += (delta * X[i][:, np.newaxis]).T\n",
        "                self.dual_coef_[:, i] += delta\n",
        "            if it == 0:\n",
        "                violation_init = violation_sum\n",
        "            vratio = violation_sum / violation_init\n",
        "            if vratio < self.tol:\n",
        "                if self.verbose >= 1:\n",
        "                    print(\"Converged\")\n",
        "                break\n",
        "        return self\n",
        "    def predict(self, X):\n",
        "        decision = np.dot(X, self.coef_.T)\n",
        "        pred = decision.argmax(axis=1)\n",
        "        return self._label_encoder.inverse_transform(pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "4NcfaiZmM2hx",
        "outputId": "90cbaf91-a9a1-4ad4-9637-d4c33174bb2f"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-57a460a776c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMulticlassSVM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ],
      "source": [
        "clf = MulticlassSVM(C=0.25, tol=0.01, max_iter=1000, random_state=0, verbose=1)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "print(clf.score(X_train, y_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QsxY4sGqNY_1"
      },
      "outputs": [],
      "source": [
        "print(clf.score(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5wXpozawDDsW"
      },
      "outputs": [],
      "source": [
        "hasil = clf.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dMduu3k5NcQ9"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "print(\"SVM Accuracy: \", accuracy_score(y_test, hasil))\n",
        "print(\"SVM Precision: \", precision_score(y_test, hasil, average='weighted'))\n",
        "print(\"SVM Recall: \", recall_score(y_test, hasil, average='weighted'))\n",
        "print(\"SVM f1_score: \", f1_score(y_test, hasil, average='weighted'))\n",
        "\n",
        "print(classification_report(y_test, hasil, zero_division=0))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix(y_test, hasil)\n",
        "\n",
        "fig, ax = plt.subplots(figsize = (8,6))\n",
        "sns.heatmap(confusion_matrix(y_true = y_test, y_pred = hasil), fmt = 'g', annot = True,   cmap='Blues_r')\n",
        "ax.xaxis.set_label_position('top')\n",
        "ax.xaxis.set_ticks_position('top')\n",
        "ax.set_xlabel('Prediction', fontsize = 14)\n",
        "ax.set_xticklabels([ 'postive (2)','neutral (0)', 'negative (1)' ])\n",
        "ax.set_ylabel('Actual', fontsize = 14)\n",
        "ax.set_yticklabels([ 'postive (2)','neutral (0)', 'negative (1)'] )\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pQObq9Eq4LwK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **SOFT** **VOTING**"
      ],
      "metadata": {
        "id": "oEE5EkCz2XLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Bobot** **Manual**"
      ],
      "metadata": {
        "id": "jTiK8awpPpRo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC"
      ],
      "metadata": {
        "id": "OE9DsKoT-q2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Membuat objek untuk setiap model\n",
        "model_rf =  RandomForestClassifier(n_estimators=200, max_depth=13, criterion='entropy')\n",
        "model_xgb = XGBClassifier(max_depth=13, n_estimators=200, learning_rate=0.05)\n",
        "model_svm = SVC(C=10, kernel='rbf', probability=True)\n",
        "\n",
        "# Menggabungkan model dengan VotingClassifier dan menentukan bobot untuk setiap model\n",
        "voting_clf = VotingClassifier(estimators=[('rf', model_rf), ('xgb', model_xgb), ('svm', model_svm)],\n",
        "                              voting='soft', weights=[0.4, 0.2, 0.4])"
      ],
      "metadata": {
        "id": "h1-VaKqmvi_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Melatih model VotingClassifier\n",
        "voting_clf.fit(X_train, y_train)\n",
        "\n",
        "# Membuat prediksi menggunakan model VotingClassifier\n",
        "y_pred = voting_clf.predict(X_test)"
      ],
      "metadata": {
        "id": "t5EU8VDwvlWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "voting_clf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "9yFiGrecNNqK",
        "outputId": "860016f8-f943-46ff-9e4a-6f6e56e6e7fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VotingClassifier(estimators=[('rf',\n",
              "                              RandomForestClassifier(criterion='entropy',\n",
              "                                                     max_depth=13,\n",
              "                                                     n_estimators=200)),\n",
              "                             ('xgb',\n",
              "                              XGBClassifier(base_score=None, booster=None,\n",
              "                                            callbacks=None,\n",
              "                                            colsample_bylevel=None,\n",
              "                                            colsample_bynode=None,\n",
              "                                            colsample_bytree=None,\n",
              "                                            early_stopping_rounds=None,\n",
              "                                            enable_categorical=False,\n",
              "                                            eval_metric=None,\n",
              "                                            feature_types=None, gamma=None,\n",
              "                                            gpu_id=No...\n",
              "                                            learning_rate=0.05, max_bin=None,\n",
              "                                            max_cat_threshold=None,\n",
              "                                            max_cat_to_onehot=None,\n",
              "                                            max_delta_step=None, max_depth=13,\n",
              "                                            max_leaves=None,\n",
              "                                            min_child_weight=None, missing=nan,\n",
              "                                            monotone_constraints=None,\n",
              "                                            n_estimators=200, n_jobs=None,\n",
              "                                            num_parallel_tree=None,\n",
              "                                            predictor=None, random_state=None, ...)),\n",
              "                             ('svm', SVC(C=10, probability=True))],\n",
              "                 voting='soft', weights=[0.4, 0.2, 0.4])"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;rf&#x27;,\n",
              "                              RandomForestClassifier(criterion=&#x27;entropy&#x27;,\n",
              "                                                     max_depth=13,\n",
              "                                                     n_estimators=200)),\n",
              "                             (&#x27;xgb&#x27;,\n",
              "                              XGBClassifier(base_score=None, booster=None,\n",
              "                                            callbacks=None,\n",
              "                                            colsample_bylevel=None,\n",
              "                                            colsample_bynode=None,\n",
              "                                            colsample_bytree=None,\n",
              "                                            early_stopping_rounds=None,\n",
              "                                            enable_categorical=False,\n",
              "                                            eval_metric=None,\n",
              "                                            feature_types=None, gamma=None,\n",
              "                                            gpu_id=No...\n",
              "                                            learning_rate=0.05, max_bin=None,\n",
              "                                            max_cat_threshold=None,\n",
              "                                            max_cat_to_onehot=None,\n",
              "                                            max_delta_step=None, max_depth=13,\n",
              "                                            max_leaves=None,\n",
              "                                            min_child_weight=None, missing=nan,\n",
              "                                            monotone_constraints=None,\n",
              "                                            n_estimators=200, n_jobs=None,\n",
              "                                            num_parallel_tree=None,\n",
              "                                            predictor=None, random_state=None, ...)),\n",
              "                             (&#x27;svm&#x27;, SVC(C=10, probability=True))],\n",
              "                 voting=&#x27;soft&#x27;, weights=[0.4, 0.2, 0.4])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;rf&#x27;,\n",
              "                              RandomForestClassifier(criterion=&#x27;entropy&#x27;,\n",
              "                                                     max_depth=13,\n",
              "                                                     n_estimators=200)),\n",
              "                             (&#x27;xgb&#x27;,\n",
              "                              XGBClassifier(base_score=None, booster=None,\n",
              "                                            callbacks=None,\n",
              "                                            colsample_bylevel=None,\n",
              "                                            colsample_bynode=None,\n",
              "                                            colsample_bytree=None,\n",
              "                                            early_stopping_rounds=None,\n",
              "                                            enable_categorical=False,\n",
              "                                            eval_metric=None,\n",
              "                                            feature_types=None, gamma=None,\n",
              "                                            gpu_id=No...\n",
              "                                            learning_rate=0.05, max_bin=None,\n",
              "                                            max_cat_threshold=None,\n",
              "                                            max_cat_to_onehot=None,\n",
              "                                            max_delta_step=None, max_depth=13,\n",
              "                                            max_leaves=None,\n",
              "                                            min_child_weight=None, missing=nan,\n",
              "                                            monotone_constraints=None,\n",
              "                                            n_estimators=200, n_jobs=None,\n",
              "                                            num_parallel_tree=None,\n",
              "                                            predictor=None, random_state=None, ...)),\n",
              "                             (&#x27;svm&#x27;, SVC(C=10, probability=True))],\n",
              "                 voting=&#x27;soft&#x27;, weights=[0.4, 0.2, 0.4])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>rf</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, max_depth=13, n_estimators=200)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>xgb</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=13, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              n_estimators=200, n_jobs=None, num_parallel_tree=None,\n",
              "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>svm</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=10, probability=True)</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HluTTUQ9_RWc",
        "outputId": "5f0480d8-b7fe-4fcb-c074-57d17fc33bea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8137755102040817\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **FIREFLY**"
      ],
      "metadata": {
        "id": "-4xiy6_BvIlb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import xgboost as xgb\n",
        "from sklearn.svm import SVC\n",
        "from scipy.spatial.distance import euclidean\n",
        "\n",
        "# define the objective function\n",
        "def objective_function(weights, clf_list, X_train, y_train, X_val, y_val):\n",
        "    weighted_sum = 0\n",
        "    for i in range(len(clf_list)):\n",
        "        clf = clf_list[i]\n",
        "        clf.fit(X_train, y_train)\n",
        "        weighted_sum += weights[i] * clf.score(X_val, y_val)\n",
        "    return weighted_sum\n",
        "\n",
        "# define the firefly algorithm\n",
        "def firefly_algorithm(clf_list, X_train, y_train, X_test, y_test, n_fireflies, n_iterations, gamma):\n",
        "    # initialization\n",
        "    n_clfs = len(clf_list)\n",
        "    lb = np.zeros(n_clfs)  # lower bound\n",
        "    ub = np.ones(n_clfs)   # upper bound\n",
        "    fireflies = np.random.uniform(0, 1, size=(n_fireflies, n_clfs))\n",
        "    best_weights = np.zeros(n_clfs)\n",
        "    best_fitness = -1\n",
        "    \n",
        "    # main loop\n",
        "    for i in range(n_iterations):\n",
        "        # evaluate fitness\n",
        "        fitness = np.zeros(n_fireflies)\n",
        "        for j in range(n_fireflies):\n",
        "            fitness[j] = objective_function(fireflies[j], clf_list, X_train, y_train, X_test, y_test)\n",
        "        \n",
        "        # update best solution\n",
        "        index = np.argmax(fitness)\n",
        "        if fitness[index] > best_fitness:\n",
        "            best_fitness = fitness[index]\n",
        "            best_weights = fireflies[index]\n",
        "        \n",
        "        # move fireflies\n",
        "        for j in range(n_fireflies):\n",
        "            for k in range(n_fireflies):\n",
        "                if fitness[j] < fitness[k]:\n",
        "                    r = euclidean(fireflies[j], fireflies[k])\n",
        "                    beta = 1 / (1 + gamma*r**2)\n",
        "                    fireflies[j] = fireflies[j] + beta*(fireflies[k] - fireflies[j]) + np.random.normal(0, 0.01, size=n_clfs)\n",
        "        \n",
        "        # constrain to bounds\n",
        "        fireflies = np.clip(fireflies, lb, ub)\n",
        "    \n",
        "    return best_weights\n",
        "\n",
        "# example usage\n",
        "rf = RandomForestClassifier()\n",
        "xgb = xgb.XGBClassifier()\n",
        "svm = SVC()\n",
        "\n",
        "clf_list = [rf, xgb, svm]\n",
        "\n",
        "# assume X_train, y_train, X_test, y_test are defined\n",
        "\n",
        "n_fireflies = 10\n",
        "n_iterations = 100\n",
        "gamma = 1\n",
        "\n",
        "weights = firefly_algorithm(clf_list, X_train, y_train, X_test, y_test, n_fireflies, n_iterations, gamma)\n",
        "\n",
        "print(weights)\n",
        "\n"
      ],
      "metadata": {
        "id": "htaV5ddLu9R8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PSO**"
      ],
      "metadata": {
        "id": "CDXp-qamYmlx"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "WVbFCPIspaam",
        "JJULK14jzBwb",
        "vaY9VqEDzHCi",
        "jTiK8awpPpRo"
      ],
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}